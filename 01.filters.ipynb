{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python361064bitmyenvcondab57de20f7ef74e49a8177e6a8e674dc1",
      "display_name": "Python 3.6.10 64-bit ('myenv': conda)"
    },
    "colab": {
      "name": "Copy of Intro to Image Processing  - Helen",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgtM_NFfalWB",
        "colab_type": "text"
      },
      "source": [
        "# Filters: Image Processing Tutorial\n",
        "\n",
        "In this tutorial notebook, you will:\n",
        "- Get familiar with basic image processing with OpenCV (reading images, displaying images, etc.)\n",
        "- Learn how filters and convolution work.\n",
        "\n",
        "## Reading and Displaying Images with OpenCV\n",
        "\n",
        "In order to take advantage of OpenCV, we first need to install it (if it is not installed yet) and import it in this notebook. We would also need to install the `matplotlib` library in order to display images in this notebook. Finally, we will also import `numpy` in otder to access the image data in matrix form."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEJGKjJCbcA4",
        "colab_type": "code",
        "outputId": "5eda8442-135f-41cc-f0f4-dca9ff027c1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# This cell improts the data and images needed for this notebook to be functional\n",
        "!git clone https://github.com/imadtoubal/Image-Processing-Tutorial-Assets.git\n",
        "!mv Image-Processing-Tutorial-Assets/* .\n",
        "!rm -rf Image-Processing-Tutorial-Assets"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Image-Processing-Tutorial-Assets'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 6 (delta 0), reused 6 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (6/6), done.\n",
            "mv: cannot move 'Image-Processing-Tutorial-Assets/assets' to './assets': Directory not empty\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R08SM5RRalWD",
        "colab_type": "code",
        "outputId": "9d01ad7b-230a-46dd-80a9-f87027ec39dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "!pip install opencv-python\n",
        "!pip install matplotlib"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.18.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.18.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn10Tb8NalWH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTJOaH1falWK",
        "colab_type": "text"
      },
      "source": [
        "In order to read an image, we can use the built in function in OpenCV, `cv2.imread`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_tvB20-alWK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im = cv2.imread('assets/fmnist.png')\n",
        "im.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBXEOPZsalWN",
        "colab_type": "text"
      },
      "source": [
        "There are two things to note here:\n",
        "- First, the image is saved into a numpy array. This means that we can index it as a numpy array, we can also use numpy functions like `np.mean`.\n",
        "- Even though we have a 2-dimensional image, our numpy array has a third dimension of size 3. This actually represents the different **channels** of the image: Red, Green, and Blue (or RGB for short). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGLRDK_nalWO",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 1:** `matplotlib.pyplot` provides functionality to draw different types of graphs and visualizations. This package also gives functionality to display an image using `imshow`. In the following cell, pass the image as a parameter to the `plt.imshow` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M30kWX7HalWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(im)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRViVsZAalWR",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 2:** Even though we have 3 channels in out image, it seems that the picture is actually grayscale. Write code to convert it into a greyscale image (Hint: use `numpy` to get the average across the third dimension)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTxSVW6galWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im = <YOUR CODE HERE>\n",
        "im.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dJSOQwBalWU",
        "colab_type": "text"
      },
      "source": [
        "The picture above is a subset of (Fashion-MNIST)[https://github.com/zalandoresearch/fashion-mnist] dataset. Notice how the pictures are all displayed in a grid of 10x10 total images. \n",
        "\n",
        "**Exercise 2:** Using the information above and the `shape` of the full image, find the dimension `d` of each sub-image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpwQ8euEalWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = <YOUR CODE HERE>\n",
        "print (d)\n",
        "print(f\"Sub-images are of shape {d}x{d}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9thmqrEalWX",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 3:** Now that we know the actual size of sample images, can we use that information to get a part of the image that represents the sub-image in the first row and first column of the grid?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7cq3WODalWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subim = <YOUR CODE HERE>\n",
        "plt.imshow(subim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdsbkPmlalWa",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://)Notice how the `imshow` function in `matplotlib` package by defult uses a colormap that takes value from dark-blue to yellow for grayscale images. In order to use a black to white colormap, we can pass the parameter `cmap='gray'` to the `imshow` function as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qx1Ma9dialWb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(subim, cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suwhkjxKalWd",
        "colab_type": "text"
      },
      "source": [
        "## Spatial Filters (Convolution)\n",
        "\n",
        "In image processing, applying a filter is modifying each pixel of an image based on its neighborhood value. To understand what that means, refer to the animation below:\n",
        "\n",
        "<center><img alt=\"2D Convolution\" src=\"https://upload.wikimedia.org/wikipedia/commons/1/19/2D_Convolution_Animation.gif\"/></center>\n",
        "\n",
        "\n",
        "*Source: https://commons.m.wikimedia.org/wiki/File:2D_Convolution_Animation.gif*\n",
        "\n",
        "The two main components (or inputs) to this operation are:\n",
        "\n",
        "1. **The input image $I$ :** the image we want to apply our filter on, and\n",
        "2. **The kernel $K$ (or filter):** an n×n matrix.\n",
        "\n",
        "If we assume a 3×3 convolution, let us consider every pixel $I(x, y)$ of the input image (where $x\\in[0, W]$ and $y\\in[0, H]$): each pixel $I_{out}(x,y)$ of the output image is calculated as follows:\n",
        "\n",
        "$$I_{out}(x, y)=\\sum_{i = x-1}^{x+1}\\sum_{j = y-1}^{y+1}I(i, j) \\times K(i-1, j-1)$$\n",
        "\n",
        "Note that the above equation would fail in edge cases ($x = 0$, $x = W-1$, $y = 0$ or $y = H$). In the previous animation, a \"padding\" was added to the input image as a first step; then, convolution was applied to that padded image in order to produce an output of the same size as the input. For now, we can just skip edge pixels.\n",
        "\n",
        "****\n",
        "\n",
        "**Exercise 4:** To better understand convolution, let's build our own convolution function `conv` that takes as a parameter the input image `img` and the `kernel`. **Implement the convolution function defined below.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07zIoqnDalWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv(img, kernel):\n",
        "    # Create an empty image of the same size of th input\n",
        "    img_out = np.zeros_like(img)\n",
        "\n",
        "    # Store width and height for later use\n",
        "    H, W = img.shape\n",
        "    kH, kW = kernel.shape\n",
        "    \n",
        "    # Loop through the pixels of the image\n",
        "    <YOUR CODE HERE>\n",
        "\n",
        "    return img_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hy_DRyAbalWi",
        "colab_type": "text"
      },
      "source": [
        "In order to test our code, let us use the following kernel:\n",
        "\n",
        "$$K=\\begin{bmatrix}-1 & 0 & 1\\\\-1 & 0 & 1\\\\-1 & 0 & 1\\end{bmatrix}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fL5npjARalWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kernel = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]])\n",
        "out = conv(subim, kernel)\n",
        "plt.imshow(out, cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAOsfVu8alWl",
        "colab_type": "text"
      },
      "source": [
        "The kernel (filter) we used is called Prewitt gradient edge detector. As the name implies, this filter is used to detect edges in the input image. Notice how it highlighted the edges of the shirt. In fact, the filter we used only highlights the vertical edges. We can use the transpose of that kernel as a horiontal edge detector:\n",
        "\n",
        "$$K'=\\begin{bmatrix}-1 & -1 & -1\\\\0 & 0 & 0\\\\1 & 1 & 1\\end{bmatrix}$$\n",
        "\n",
        "****\n",
        "**Exercise 5:** Use the function we built in Exercise 4 with the new kernel to detect horizontal edges."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o-jfUu9alWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kernel = np.array([[-1, -1, -1], [0, 0, 0], [1, 1, 1]])\n",
        "out = <YOUR CODE HERE>\n",
        "plt.imshow(out, cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJP3Gh-SalWn",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 6:** Fortunately, the OpenCV library provides a function for convolution `cv2.filter2D`. Use the OpenCV built in function for convolution to apply kernel $K$ on the image `subim`. (Hint: use [`cv2.filter2D` Documentation](https://docs.opencv.org/master/d4/d13/tutorial_py_filtering.html) as a resource to know how to use the function)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hts3d2MIalWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = <YOUR CODE HERE>\n",
        "plt.imshow(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Un6tGc0q5eKT",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 7:** Experiment with diffirent types of kernels. One example would be the following:\n",
        "$$K_g = \\begin{bmatrix}1 & 2 & 1\\\\1 & 2 & 1\\\\1 & 2 & 1\\end{bmatrix}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvEm852KalWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "<YOUR CODE HERE>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZ6Vm9SHTX5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}